{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nkubana0/FuelTrend/blob/main/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import joblib\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "rfj2qJ9556Sx"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classical ML\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "bGXFqzO959JW"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural Networks\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import regularizers"
      ],
      "metadata": {
        "id": "DJpdl8YE6Er4"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load and preprocess data\n",
        "def load_data():\n",
        "    gasoline_url = \"https://prod-energy-fuel-prices.s3.amazonaws.com/wholesalegasolineprices.csv\"\n",
        "    diesel_url = \"https://prod-energy-fuel-prices.s3.amazonaws.com/wholesaledieselprices.csv\"\n",
        "\n",
        "    gas_df = pd.read_csv(gasoline_url)\n",
        "    diesel_df = pd.read_csv(diesel_url)\n",
        "\n",
        "    print(\"Gasoline DF columns:\", gas_df.columns.tolist())\n",
        "    print(\"Diesel DF columns:\", diesel_df.columns.tolist())\n",
        "\n",
        "    gas_df['Date'] = pd.to_datetime(gas_df['Date'], errors='coerce')\n",
        "    diesel_df['Date'] = pd.to_datetime(diesel_df['Date'], errors='coerce')\n",
        "\n",
        "    gas_df.rename(columns={\n",
        "        \"Date\": \"date\",\n",
        "        \"Day-of Toronto Wholesale Gasoline  / Prix de gros de l’essence à Toronto\": \"gasoline_price\"\n",
        "        }, inplace=True)\n",
        "    diesel_df.rename(columns={\n",
        "        \"Date\": \"date\",\n",
        "        \"Day-of Toronto Wholesale Diesel  / Prix de gros du diesel à Toronto\": \"diesel_price\"\n",
        "        }, inplace=True)\n",
        "\n",
        "    df = pd.merge(gas_df[['date', 'gasoline_price']], diesel_df[['date', 'diesel_price']], on='date', how='inner')\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "Wwc-FfKf6HfU"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Feature Engineering\n",
        "def feature_engineering(df):\n",
        "    df['month'] = df['date'].dt.month\n",
        "    df['year'] = df['date'].dt.year\n",
        "    df = df.ffill()\n",
        "\n",
        "    # 3-class target: Low / Medium / High gasoline price\n",
        "    df['price_category'] = pd.qcut(df['gasoline_price'], q=3, labels=[0, 1, 2])\n",
        "\n",
        "    # Show class balance\n",
        "    print(\"Class balance (price_category):\")\n",
        "    print(df['price_category'].value_counts())\n",
        "    print(df['price_category'].value_counts(normalize=True))\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "EEi9_Bk-6KNP"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare X and y\n",
        "def prepare_xy(df, target_column=\"price_category\"):\n",
        "    X = df.drop(columns=[\"date\", \"gasoline_price\", target_column])\n",
        "    y = df[target_column].astype(int)\n",
        "    return train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "YfdwSWsN6Lyz"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classical ML: XGBClassifier\n",
        "def train_logistic_regression(X_train, y_train, X_val, y_val):\n",
        "    model = LogisticRegression(C=1.0, penalty='l2', solver='lbfgs', max_iter=500, multi_class='multinomial')\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_val)\n",
        "    acc = accuracy_score(y_val, preds)\n",
        "    prec = precision_score(y_val, preds, average='macro')\n",
        "    rec = recall_score(y_val, preds, average='macro')\n",
        "    f1 = f1_score(y_val, preds, average='macro')\n",
        "    return model, acc, prec, rec, f1"
      ],
      "metadata": {
        "id": "D53HF_Vn6N4q"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural Network — Simple\n",
        "def build_simple_nn(input_dim, num_classes):\n",
        "    model = Sequential([\n",
        "        Input(shape=(input_dim,)),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "eq0SlDBu6P6Y"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural Network — Optimized\n",
        "def build_optimized_nn(input_dim, optimizer, regularizer=None, dropout_rate=None, num_classes=3):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(input_dim,)))\n",
        "    model.add(Dense(128, activation='relu', kernel_regularizer=regularizer))\n",
        "    if dropout_rate:\n",
        "        model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(64, activation='relu', kernel_regularizer=regularizer))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "jCVI3pu26Tk_"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save models\n",
        "def save_sklearn_model(model, name):\n",
        "    os.makedirs(\"saved_models\", exist_ok=True)\n",
        "    joblib.dump(model, f\"saved_models/{name}.pkl\")\n",
        "\n",
        "def save_keras_model(model, name):\n",
        "    os.makedirs(\"saved_models\", exist_ok=True)\n",
        "    model.save(f\"saved_models/{name}.h5\")"
      ],
      "metadata": {
        "id": "9BrxSsYC6VdE"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model\n",
        "def evaluate_model(model, X_val, y_val):\n",
        "    preds = model.predict(X_val)\n",
        "    if preds.ndim > 1:  # NN outputs\n",
        "        preds = np.argmax(preds, axis=1)\n",
        "    acc = accuracy_score(y_val, preds)\n",
        "    prec = precision_score(y_val, preds, average='macro')\n",
        "    rec = recall_score(y_val, preds, average='macro')\n",
        "    f1 = f1_score(y_val, preds, average='macro')\n",
        "    return acc, prec, rec, f1"
      ],
      "metadata": {
        "id": "hLIVAay96XQ8"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main execution\n",
        "if __name__ == '__main__':\n",
        "    # Load and prepare data\n",
        "    df = load_data()\n",
        "    df = feature_engineering(df)\n",
        "    X_train, X_val, y_train, y_val = prepare_xy(df, target_column=\"price_category\")\n",
        "\n",
        "    # Logistic Regression\n",
        "    lr_model, acc, prec, rec, f1 = train_logistic_regression(X_train, y_train, X_val, y_val)\n",
        "    print(\"Logistic Regression Results:\", acc, prec, rec, f1)\n",
        "    save_sklearn_model(lr_model, \"logistic_regression_model\")\n",
        "\n",
        "    # Simple NN\n",
        "    nn_simple = build_simple_nn(X_train.shape[1], num_classes=3)\n",
        "    nn_simple.fit(X_train, y_train, epochs=10, verbose=0)\n",
        "    acc, prec, rec, f1 = evaluate_model(nn_simple, X_val, y_val)\n",
        "    print(\"NN Simple Results:\", acc, prec, rec, f1)\n",
        "    save_keras_model(nn_simple, \"nn_simple\")\n",
        "\n",
        "    # Optimized NN — Instance 1\n",
        "    nn_opt1 = build_optimized_nn(\n",
        "        X_train.shape[1],\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "        regularizer=None,\n",
        "        dropout_rate=None\n",
        "    )\n",
        "    es = EarlyStopping(monitor='val_loss', patience=5)\n",
        "    nn_opt1.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val), callbacks=[es], verbose=0)\n",
        "    acc, prec, rec, f1 = evaluate_model(nn_opt1, X_val, y_val)\n",
        "    print(\"NN Optimized 1 Results:\", acc, prec, rec, f1)\n",
        "    save_keras_model(nn_opt1, \"nn_optimized_1\")\n",
        "\n",
        "    # Optimized NN — Instance 2\n",
        "    nn_opt2 = build_optimized_nn(\n",
        "        X_train.shape[1],\n",
        "        optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0005),\n",
        "        regularizer=regularizers.l2(0.001),\n",
        "        dropout_rate=0.2\n",
        "    )\n",
        "    nn_opt2.fit(X_train, y_train, epochs=75, validation_data=(X_val, y_val), callbacks=[es], verbose=0)\n",
        "    acc, prec, rec, f1 = evaluate_model(nn_opt2, X_val, y_val)\n",
        "    print(\"NN Optimized 2 Results:\", acc, prec, rec, f1)\n",
        "    save_keras_model(nn_opt2, \"nn_optimized_2\")\n",
        "\n",
        "    # You can add more optimized instances (3, 4, 5) the same way!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXGNh35W6Z3n",
        "outputId": "7061911a-8083-46f0-f8b2-477b64a0e21f"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gasoline DF columns: ['Date', 'Day-of Toronto Wholesale Gasoline  / Prix de gros de l’essence à Toronto', 'Prior Day NY Harbor Spot / Détaillant au port de NY le jour précédent', 'Day-of Toronto less Prior Day NY Harbor / Prix de gros à Toronto moins le prix au port de NY', 'Day-of Thunder Bay Wholesale Gasoline  / Prix de gros de l’essence à Thunder Bay', 'Prior Day Edmonton Spot / Détaillant au Edmonton le jour précédent', 'Day-of Thunder Bay less Prior Day Edmonton / Prix de gros à Thunder Bay moins le prix au Edmonton']\n",
            "Diesel DF columns: ['Date', 'Day-of Toronto Wholesale Diesel  / Prix de gros du diesel à Toronto', 'Prior Day NY Harbor Spot / Détaillant au port de NY le jour précédent', 'Day-of Toronto less Prior Day NY Harbor / Prix de gros à Toronto moins le prix au port de NY', 'Day-of Thunder Bay Wholesale Diesel  / Prix de gros du diesel à Thunder Bay', 'Prior Day Edmonton Spot / Détaillant au Edmonton le jour précédent', 'Day-of Thunder Bay less Prior Day Edmonton / Prix de gros à Thunder Bay moins le prix au Edmonton']\n",
            "Class balance (price_category):\n",
            "price_category\n",
            "0    470\n",
            "2    463\n",
            "1    456\n",
            "Name: count, dtype: int64\n",
            "price_category\n",
            "0    0.338373\n",
            "2    0.333333\n",
            "1    0.328294\n",
            "Name: proportion, dtype: float64\n",
            "Logistic Regression Results: 0.7230215827338129 0.7211734349689052 0.7211734349689052 0.7211734349689052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NN Simple Results: 0.60431654676259 0.6128162858952976 0.6028176048766303 0.5680104934021175\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NN Optimized 1 Results: 0.5539568345323741 0.3847903176071539 0.5484252268740945 0.44049038843791277\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NN Optimized 2 Results: 0.5575539568345323 0.7033509700176367 0.5567740427040359 0.46182465642072623\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRkfUjIgwnahrWNK/BoYik",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}