{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nkubana0/FuelTrend/blob/main/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import joblib\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import regularizers"
      ],
      "metadata": {
        "id": "rfj2qJ9556Sx"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load data\n",
        "def load_data():\n",
        "    gasoline_url = \"https://prod-energy-fuel-prices.s3.amazonaws.com/wholesalegasolineprices.csv\"\n",
        "    diesel_url = \"https://prod-energy-fuel-prices.s3.amazonaws.com/wholesaledieselprices.csv\"\n",
        "\n",
        "    gas_df = pd.read_csv(gasoline_url)\n",
        "    diesel_df = pd.read_csv(diesel_url)\n",
        "\n",
        "    gas_df['Date'] = pd.to_datetime(gas_df['Date'], errors='coerce')\n",
        "    diesel_df['Date'] = pd.to_datetime(diesel_df['Date'], errors='coerce')\n",
        "\n",
        "    gas_df.rename(columns={\n",
        "        \"Date\": \"date\",\n",
        "        \"Day-of Toronto Wholesale Gasoline  / Prix de gros de l’essence à Toronto\": \"gasoline_price\"\n",
        "    }, inplace=True)\n",
        "\n",
        "    diesel_df.rename(columns={\n",
        "        \"Date\": \"date\",\n",
        "        \"Day-of Toronto Wholesale Diesel  / Prix de gros du diesel à Toronto\": \"diesel_price\"\n",
        "    }, inplace=True)\n",
        "\n",
        "    df = pd.merge(gas_df[['date', 'gasoline_price']], diesel_df[['date', 'diesel_price']], on='date', how='inner')\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "Wwc-FfKf6HfU"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Feature Engineering\n",
        "def feature_engineering(df):\n",
        "    df['month'] = df['date'].dt.month\n",
        "    df['year'] = df['date'].dt.year\n",
        "    df = df.ffill()\n",
        "\n",
        "    df['price_category'] = pd.qcut(df['gasoline_price'], q=3, labels=[0, 1, 2])\n",
        "\n",
        "    print(\"Class balance (price_category):\")\n",
        "    print(df['price_category'].value_counts())\n",
        "    print(df['price_category'].value_counts(normalize=True))\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "EEi9_Bk-6KNP"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare X and y\n",
        "def prepare_xy(df, target_column=\"price_category\"):\n",
        "    X = df.drop(columns=[\"date\", \"gasoline_price\", target_column])\n",
        "    y = df[target_column].astype(int)\n",
        "    return train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "YfdwSWsN6Lyz"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save models\n",
        "def save_sklearn_model(model, name):\n",
        "    os.makedirs(\"saved_models\", exist_ok=True)\n",
        "    joblib.dump(model, f\"saved_models/{name}.pkl\")\n",
        "\n",
        "def save_keras_model(model, name):\n",
        "    os.makedirs(\"saved_models\", exist_ok=True)\n",
        "    model.save(f\"saved_models/{name}.h5\")"
      ],
      "metadata": {
        "id": "9BrxSsYC6VdE"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model\n",
        "def evaluate_model(model, X_val, y_val):\n",
        "    preds = model.predict(X_val)\n",
        "    if preds.ndim > 1:\n",
        "        preds = np.argmax(preds, axis=1)\n",
        "    acc = accuracy_score(y_val, preds)\n",
        "    prec = precision_score(y_val, preds, average='macro')\n",
        "    rec = recall_score(y_val, preds, average='macro')\n",
        "    f1 = f1_score(y_val, preds, average='macro')\n",
        "    return acc, prec, rec, f1"
      ],
      "metadata": {
        "id": "hLIVAay96XQ8"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ML model\n",
        "def train_logistic_regression(X_train, y_train, X_val, y_val):\n",
        "    model = LogisticRegression(C=1.0, penalty='l2', solver='lbfgs', max_iter=500)\n",
        "    model.fit(X_train, y_train)\n",
        "    return model, evaluate_model(model, X_val, y_val)"
      ],
      "metadata": {
        "id": "VTvjiBwfT4SC"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#NN simple\n",
        "def build_simple_nn(input_dim, num_classes):\n",
        "    model = Sequential([\n",
        "        Input(shape=(input_dim,)),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "mYhnIgX0ULka"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#NN optimized\n",
        "def build_optimized_nn(input_dim, optimizer, regularizer=None, dropout_rate=None, num_classes=3):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(input_dim,)))\n",
        "    model.add(Dense(128, activation='relu', kernel_regularizer=regularizer))\n",
        "    if dropout_rate:\n",
        "        model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(64, activation='relu', kernel_regularizer=regularizer))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "emn1ZKSBUP21"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main execution\n",
        "if __name__ == '__main__':\n",
        "    df = load_data()\n",
        "    df = feature_engineering(df)\n",
        "\n",
        "    # Train/Val/Test split\n",
        "    train_df, test_df = train_test_split(df, test_size=0.15, random_state=42, stratify=df['price_category'])\n",
        "    X_train, X_val, y_train, y_val = prepare_xy(train_df, target_column=\"price_category\")\n",
        "    X_test = test_df.drop(columns=[\"date\", \"gasoline_price\", \"price_category\"])\n",
        "    y_test = test_df[\"price_category\"].astype(int)\n",
        "\n",
        "    # Logistic Regression\n",
        "    lr_model, (acc, prec, rec, f1) = train_logistic_regression(X_train, y_train, X_val, y_val)\n",
        "    print(\"Logistic Regression:\", acc, prec, rec, f1)\n",
        "    save_sklearn_model(lr_model, \"logistic_regression_model\")\n",
        "\n",
        "    # NN Simple\n",
        "    nn_simple = build_simple_nn(X_train.shape[1], 3)\n",
        "    nn_simple.fit(X_train, y_train, epochs=10, verbose=0)\n",
        "    acc, prec, rec, f1 = evaluate_model(nn_simple, X_val, y_val)\n",
        "    print(\"NN Simple:\", acc, prec, rec, f1)\n",
        "    save_keras_model(nn_simple, \"nn_simple\")\n",
        "\n",
        "    # NN Optimized Instance 1\n",
        "    nn1 = build_optimized_nn(X_train.shape[1], optimizer=tf.keras.optimizers.Adam())\n",
        "    nn1.fit(X_train, y_train, epochs=20, verbose=0)\n",
        "    acc, prec, rec, f1 = evaluate_model(nn1, X_val, y_val)\n",
        "    print(\"NN Opt 1:\", acc, prec, rec, f1)\n",
        "    save_keras_model(nn1, \"nn_optimized_1\")\n",
        "\n",
        "    # NN Optimized Instance 2\n",
        "    nn2 = build_optimized_nn(X_train.shape[1], optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
        "    es = EarlyStopping(monitor='val_loss', patience=5)\n",
        "    nn2.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val), callbacks=[es], verbose=0)\n",
        "    acc, prec, rec, f1 = evaluate_model(nn2, X_val, y_val)\n",
        "    print(\"NN Opt 2:\", acc, prec, rec, f1)\n",
        "    save_keras_model(nn2, \"nn_optimized_2\")\n",
        "\n",
        "    # NN Optimized Instance 3\n",
        "    nn3 = build_optimized_nn(\n",
        "        X_train.shape[1],\n",
        "        optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0005),\n",
        "        regularizer=regularizers.l2(0.001),\n",
        "        dropout_rate=0.2\n",
        "    )\n",
        "    nn3.fit(X_train, y_train, epochs=75, validation_data=(X_val, y_val), callbacks=[es], verbose=0)\n",
        "    acc, prec, rec, f1 = evaluate_model(nn3, X_val, y_val)\n",
        "    print(\"NN Opt 3:\", acc, prec, rec, f1)\n",
        "    save_keras_model(nn3, \"nn_optimized_3\")\n",
        "\n",
        "    # NN Optimized Instance 4\n",
        "    nn4 = build_optimized_nn(\n",
        "        X_train.shape[1],\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "        regularizer=regularizers.l2(0.01),\n",
        "        dropout_rate=0.3\n",
        "    )\n",
        "    nn4.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), callbacks=[es], verbose=0)\n",
        "    acc, prec, rec, f1 = evaluate_model(nn4, X_val, y_val)\n",
        "    print(\"NN Opt 4:\", acc, prec, rec, f1)\n",
        "    save_keras_model(nn4, \"nn_optimized_4\")\n",
        "\n",
        "    # Predict on test set with best model (Example with LR)\n",
        "    lr_preds = lr_model.predict(X_test)\n",
        "    test_acc = accuracy_score(y_test, lr_preds)\n",
        "    print(\"Test Accuracy (LR):\", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXGNh35W6Z3n",
        "outputId": "1fd9f6d1-cf70-4e9d-9356-61026c1fc9ae"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class balance (price_category):\n",
            "price_category\n",
            "0    470\n",
            "2    463\n",
            "1    456\n",
            "Name: count, dtype: int64\n",
            "price_category\n",
            "0    0.338373\n",
            "2    0.333333\n",
            "1    0.328294\n",
            "Name: proportion, dtype: float64\n",
            "Logistic Regression: 0.7245762711864406 0.7239090263555434 0.722542735042735 0.7231070815976476\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NN Simple: 0.6483050847457628 0.4468590076392494 0.6456196581196582 0.5235057755560762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 18 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7a768d89ac00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NN Opt 1: 0.6567796610169492 0.805835587246947 0.6541666666666667 0.5758808063102542\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7a768b5eb560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NN Opt 2: 0.576271186440678 0.4012745098039216 0.5729700854700854 0.4689858082381447\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NN Opt 3: 0.4745762711864407 0.46204620462046203 0.47500000000000003 0.3845446950710108\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NN Opt 4: 0.3305084745762712 0.11016949152542373 0.3333333333333333 0.16560509554140126\n",
            "Test Accuracy (LR): 0.7129186602870813\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvOewyV1cTH7a4009LpXPM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}